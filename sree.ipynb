{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ef5658-cbc1-4a3d-bb26-44fbbbed74de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\shara\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shara\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\shara\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shara\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shara\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\shara\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\shara\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\shara\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shara\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy pandas matplotlib opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d42b3f8-3e28-4f0f-89c0-af085c79d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 2 classes.\n",
      "Found 840 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the main dataset path (no separate val folder needed!)\n",
    "dataset_dir = r\"C:\\Users\\shara\\Downloads\\major project\\tb_1269\\archive (6)\\TB_Chest_Radiography_Database\\dataset\"\n",
    "\n",
    "# Data Augmentation & Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  \n",
    "    validation_split=0.2  # 20% of images will be used for validation\n",
    ")\n",
    "\n",
    "# Load Training Data (80% of the dataset)\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"  # Training set (80%)\n",
    ")\n",
    "\n",
    "# Load Validation Data (20% of the dataset)\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"  # Validation set (20%)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba43407-a2c1-4b08-9d2e-b42db1a820de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 2 classes.\n",
      "Found 840 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 1s/step - accuracy: 0.9235 - loss: 0.2273 - val_accuracy: 0.9952 - val_loss: 0.0203\n",
      "Epoch 2/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 998ms/step - accuracy: 0.9923 - loss: 0.0237 - val_accuracy: 0.9964 - val_loss: 0.0132\n",
      "Epoch 3/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 1s/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.9976 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 957ms/step - accuracy: 0.9965 - loss: 0.0163 - val_accuracy: 0.9988 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 966ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9929 - val_loss: 0.0168\n",
      "Epoch 6/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 963ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9988 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 990ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.9964 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9952 - val_loss: 0.0192\n",
      "Epoch 9/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 961ms/step - accuracy: 0.9975 - loss: 0.0061 - val_accuracy: 0.9976 - val_loss: 0.0087\n",
      "Epoch 10/10\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 949ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9988 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Model training complete! Saved as tb_detection_mobilenetv2.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "dataset_dir = r\"C:\\Users\\shara\\Downloads\\major project\\tb_1269\\archive (6)\\TB_Chest_Radiography_Database\\dataset\"\n",
    "\n",
    "# Data Augmentation & Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "# Load Training Data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load Validation Data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Load Pretrained MobileNetV2 (without the top layer)\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers (to use pretrained features)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers for TB detection\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)  # Prevent overfitting\n",
    "output = Dense(1, activation=\"sigmoid\")(x)  # Binary classification (TB vs Normal)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,  # You can increase epochs for better results\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"tb_detection_mobilenetv2.h5\")\n",
    "\n",
    "print(\"🎉 Model training complete! Saved as tb_detection_mobilenetv2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56ba4c8-1fd3-4c66-8ef1-65011bb27965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button, Canvas, Frame\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"tb_detection_mobilenetv2.h5\")\n",
    "\n",
    "# Set default image paths (update with actual paths)\n",
    "BG_IMAGE_MAIN = r\"C:\\Users\\shara\\Downloads\\background.jpeg\"\n",
    "BG_IMAGE_PRED = r\"C:\\Users\\shara\\Downloads\\bg-2.jpeg\"\n",
    "\n",
    "class TBDetectionApp:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"TB Detection System\")\n",
    "        self.root.geometry(\"900x600\")\n",
    "\n",
    "        # Load and display background image for main window\n",
    "        if os.path.exists(BG_IMAGE_MAIN):\n",
    "            self.bg_main = Image.open(BG_IMAGE_MAIN).resize((900, 600))\n",
    "            self.bg_main_photo = ImageTk.PhotoImage(self.bg_main)\n",
    "            \n",
    "            self.canvas = Canvas(self.root, width=900, height=600)\n",
    "            self.canvas.pack(fill=\"both\", expand=True)\n",
    "            self.canvas.create_image(0, 0, image=self.bg_main_photo, anchor=\"nw\")\n",
    "\n",
    "            # Prevent garbage collection\n",
    "            self.root.bg_main_photo = self.bg_main_photo\n",
    "        else:\n",
    "            print(\"Error: Background image for main window not found!\")\n",
    "\n",
    "        # Frame for buttons\n",
    "        frame = Frame(self.root, bg=\"white\", padx=20, pady=20)\n",
    "        frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "        Label(frame, text=\"TB Detection System\", font=(\"Arial\", 20, \"bold\"), bg=\"white\", fg=\"#333\").pack(pady=20)\n",
    "        Button(frame, text=\"Predict TB\", command=self.open_prediction_window, font=(\"Arial\", 14),\n",
    "               bg=\"#4CAF50\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "        Button(frame, text=\"Exit\", command=self.root.quit, font=(\"Arial\", 14),\n",
    "               bg=\"#f44336\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def open_prediction_window(self):\n",
    "        self.root.withdraw()  # Hide main window\n",
    "        self.pred_root = tk.Toplevel()\n",
    "        self.pred_root.title(\"TB Detection - Prediction\")\n",
    "        self.pred_root.geometry(\"900x600\")\n",
    "\n",
    "        # Load and display background image for second window\n",
    "        if os.path.exists(BG_IMAGE_PRED):\n",
    "            self.bg_pred = Image.open(BG_IMAGE_PRED).resize((900, 600))\n",
    "            self.bg_pred_photo = ImageTk.PhotoImage(self.bg_pred)\n",
    "            \n",
    "            self.canvas_pred = Canvas(self.pred_root, width=900, height=600)\n",
    "            self.canvas_pred.pack(fill=\"both\", expand=True)\n",
    "            self.canvas_pred.create_image(0, 0, image=self.bg_pred_photo, anchor=\"nw\")\n",
    "\n",
    "            # Prevent garbage collection\n",
    "            self.pred_root.bg_pred_photo = self.bg_pred_photo\n",
    "        else:\n",
    "            print(\"Error: Background image for second window not found!\")\n",
    "\n",
    "        # Frame for Upload & Prediction\n",
    "        frame = Frame(self.pred_root, bg=\"white\", padx=20, pady=20)\n",
    "        frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "        Button(frame, text=\"Upload X-Ray\", command=self.predict_tb, font=(\"Arial\", 14),\n",
    "               bg=\"#4CAF50\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "        self.image_label = Label(frame, bg=\"white\")\n",
    "        self.image_label.pack()\n",
    "\n",
    "        self.result_label = Label(frame, text=\"Prediction: \", font=(\"Arial\", 16, \"bold\"), bg=\"white\", fg=\"#333\")\n",
    "        self.result_label.pack(pady=20)\n",
    "\n",
    "        Button(frame, text=\"Back\", command=self.go_back, font=(\"Arial\", 14),\n",
    "               bg=\"#FFA500\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "        Button(frame, text=\"Exit\", command=self.pred_root.destroy, font=(\"Arial\", 14),\n",
    "               bg=\"#f44336\", fg=\"white\", padx=20, pady=10).pack(pady=10)\n",
    "\n",
    "    def go_back(self):\n",
    "        self.pred_root.destroy()\n",
    "        self.root.deiconify()  # Show main window again\n",
    "\n",
    "    def predict_tb(self):\n",
    "        file_path = filedialog.askopenfilename(title=\"Select Chest X-Ray Image\",\n",
    "                                               filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        img = self.preprocess_image(file_path)\n",
    "        prediction = model.predict(img)\n",
    "        confidence = prediction[0][0] * 100\n",
    "\n",
    "        result_text = f\"TB Detected ({confidence:.2f}%)\" if prediction[0][0] > 0.5 else f\"Normal ({100 - confidence:.2f}%)\"\n",
    "        self.result_label.config(text=f\"Prediction: {result_text}\",\n",
    "                                 fg=\"#FF0000\" if prediction[0][0] > 0.5 else \"#008000\")\n",
    "\n",
    "        self.display_image(file_path)\n",
    "\n",
    "    def preprocess_image(self, img_path):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.array(img) / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "\n",
    "    def display_image(self, img_path):\n",
    "        img = Image.open(img_path).resize((300, 300))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        self.image_label.config(image=img)\n",
    "        self.image_label.image = img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TBDetectionApp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba452e0-356f-4cf6-a186-f4faff6fb9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
